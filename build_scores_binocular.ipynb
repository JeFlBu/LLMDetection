{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37d5157b-d47b-49b6-977d-1341564a4858",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bussotti/.conda/envs/ForLLMLora/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "from tqdm import tqdm\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\n",
    "from typing import Union\n",
    "import numpy as np\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae9496b-acfa-4ebd-8595-3f6e8ed781d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task was destroyed but it is pending!\n",
      "task: <Task pending name='Task-2' coro=<Kernel.poll_control_queue() running at /home/bussotti/.conda/envs/ForLLMLora/lib/python3.10/site-packages/ipykernel/kernelbase.py:279> wait_for=<Future finished result=[<zmq.Frame(b'...c-b5c'...36B)>, <zmq.Frame(b'<IDS|MSG>')>, <zmq.Frame(b'...aa38b'...64B)>, <zmq.Frame(b'...\"202'...189B)>, <zmq.Frame(b'{}')>, <zmq.Frame(b'{}')>, ...]> cb=[_chain_future.<locals>._call_set_state() at /home/bussotti/.conda/envs/ForLLMLora/lib/python3.10/asyncio/futures.py:392]>\n"
     ]
    }
   ],
   "source": [
    "1+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b55c8e-89c1-4c98-9350-a5b4a78f4fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "1+1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0c72c9-8919-4c73-96b7-4f9f096185e5",
   "metadata": {},
   "source": [
    "# INIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13c79b59-a93d-44be-abe4-665fea403e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change according to hardware\n",
    "DEVICE_1 = \"cuda:0\"\n",
    "DEVICE_2 =\"cuda:1\"# \"cpu\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46692c59-ec68-4b79-813b-bdf63a46bb35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bussotti/.conda/envs/ForLLMLora/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.set_grad_enabled(False)\n",
    "\n",
    "observer_name = \"tiiuae/falcon-7b-instruct\"\n",
    "performer_name = \"tiiuae/falcon-7b\"\n",
    "\n",
    "identical_tokens = (AutoTokenizer.from_pretrained(observer_name).vocab ==\n",
    "                    AutoTokenizer.from_pretrained(performer_name).vocab)\n",
    "\n",
    "identical_tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7524a738-94a8-40fb-a4a9-e0ef8a57dc6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: You are currently loading Falcon using legacy code contained in the model repository. Falcon has now been fully ported into the Hugging Face transformers library. For the most up-to-date and high-performance version of the Falcon model code, please update to the latest version of transformers and then load the model without the trust_remote_code=True argument.\n",
      "\n",
      "Loading checkpoint shards: 100%|██████████████████████████████████████████████████████████| 2/2 [00:02<00:00,  1.31s/it]\n",
      "/home/bussotti/.conda/envs/ForLLMLora/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "\n",
      "WARNING: You are currently loading Falcon using legacy code contained in the model repository. Falcon has now been fully ported into the Hugging Face transformers library. For the most up-to-date and high-performance version of the Falcon model code, please update to the latest version of transformers and then load the model without the trust_remote_code=True argument.\n",
      "\n",
      "Loading checkpoint shards: 100%|██████████████████████████████████████████████████████████| 2/2 [00:02<00:00,  1.14s/it]\n"
     ]
    }
   ],
   "source": [
    "observer_model = AutoModelForCausalLM.from_pretrained(observer_name,\n",
    "                                                                   device_map={\"\": DEVICE_1},\n",
    "                                                                   trust_remote_code=True,\n",
    "                                                                   torch_dtype=torch.bfloat16)\n",
    "\n",
    "performer_model = AutoModelForCausalLM.from_pretrained(performer_name,\n",
    "                                                                     device_map={\"\": DEVICE_2},\n",
    "                                                                     trust_remote_code=True,\n",
    "                                                                     torch_dtype=torch.bfloat16)\n",
    "\n",
    "observer_model.eval()\n",
    "performer_model.eval()\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(observer_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6de570d5-126b-49cf-be94-248727cc9b12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[9856,   23,  491, 3696,  304, 7209]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize(text):\n",
    "    return tokenizer(text, return_tensors=\"pt\")\n",
    "\n",
    "tokenize(\"Hello, my dog is cute\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dbe3242b-26f0-477e-a8c7-411fc90a701a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-23.2500, -18.2500,  -9.6875,  ..., -10.6875, -12.2500,  -9.1875],\n",
       "          [-13.7500, -19.6250, -14.1250,  ..., -14.9375, -16.6250, -10.9375],\n",
       "          [-13.0625, -17.0000, -14.9375,  ..., -17.8750, -15.4375, -14.5000],\n",
       "          ...,\n",
       "          [-12.9375, -12.2500, -12.6875,  ..., -16.0000, -14.8750, -18.0000],\n",
       "          [-16.8750, -15.5625, -16.2500,  ..., -16.7500, -18.3750, -15.8125],\n",
       "          [-16.1250, -17.6250, -14.5000,  ..., -18.1250, -19.2500, -17.1250]]],\n",
       "        device='cuda:0', dtype=torch.bfloat16),\n",
       " tensor([[[-20.3750, -21.0000, -14.5625,  ..., -13.2500, -15.8750,  -8.5625],\n",
       "          [-13.0625, -18.7500, -15.1875,  ..., -15.3125, -17.1250, -11.5625],\n",
       "          [-12.5000, -17.6250, -16.6250,  ..., -17.3750, -16.2500, -14.3750],\n",
       "          ...,\n",
       "          [-10.8750, -12.3750, -11.9375,  ..., -14.1875, -14.6875, -16.6250],\n",
       "          [-14.6250, -13.8750, -16.7500,  ..., -17.6250, -19.1250, -15.6250],\n",
       "          [-13.6250, -15.5625, -14.5625,  ..., -18.5000, -19.0000, -16.6250]]],\n",
       "        device='cuda:1', dtype=torch.bfloat16))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@torch.inference_mode()\n",
    "def get_logits(encodings):\n",
    "    observer_logits = observer_model(**encodings.to(DEVICE_1)).logits\n",
    "    performer_logits = performer_model(**encodings.to(DEVICE_2)).logits\n",
    "    return observer_logits, performer_logits\n",
    "\n",
    "encoding = tokenize('''Dr. Capy Cosmos, a capybara unlike any other, astounded the scientific community with his \n",
    "groundbreaking research in astrophysics. With his keen sense of observation and unparalleled ability to interpret \n",
    "cosmic data, he uncovered new insights into the mysteries of black holes and the origins of the universe. As he \n",
    "peered through telescopes with his large, round eyes, fellow researchers often remarked that it seemed as if the \n",
    "stars themselves whispered their secrets directly to him. Dr. Cosmos not only became a beacon of inspiration to \n",
    "aspiring scientists but also proved that intellect and innovation can be found in the most unexpected of creatures.'''[:100])\n",
    "\n",
    "\n",
    "observer_logits, performer_logits = get_logits(encoding)\n",
    "observer_logits, performer_logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e0b8867-8979-4fb6-a784-ef6eb9301e62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 25, 65024])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S = observer_logits.shape[-2]\n",
    "V = observer_logits.shape[-1]\n",
    "\n",
    "observer_logits[..., :-1, :].contiguous().shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "656fb3b3-015a-44bc-863a-03fb731e2515",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 25])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding.input_ids[..., 1:].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee7650b6-7fb6-48db-aaee-2067c432a345",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.7148,  9.8125,  6.0000,  9.8125,  1.8281,  2.9688,  1.9297,  6.9375,\n",
       "           0.0425,  0.0269, 11.5000,  0.2715,  0.1387,  0.3066,  9.0625,  1.7422,\n",
       "           1.1250,  2.4531,  0.7188,  1.0938,  1.4297,  4.7188,  9.6250,  5.5938,\n",
       "           8.8750]], device='cuda:1'),\n",
       " tensor([98.7275], device='cuda:1'))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = torch.nn.CrossEntropyLoss(reduction='none')\n",
    "\n",
    "ppl = loss(observer_logits[..., :-1, :].contiguous().transpose(1, 2).to(DEVICE_2), \n",
    "     encoding.input_ids[..., 1:].contiguous().to(DEVICE_2)).float()\n",
    "\n",
    "ppl, ppl.sum(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "86724d14-2ebd-478e-9ab0-c152ed606ceb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[5.8265e-12, 3.1122e-12, 1.9500e-09,  ..., 7.2177e-09, 5.2387e-10,\n",
       "          7.8604e-07],\n",
       "         [7.5437e-08, 2.5648e-10, 9.0222e-09,  ..., 7.9744e-09, 1.3024e-09,\n",
       "          3.3900e-07],\n",
       "         [6.0536e-08, 3.6016e-10, 9.7498e-10,  ..., 4.6202e-10, 1.4188e-09,\n",
       "          9.2550e-09],\n",
       "         ...,\n",
       "         [1.3877e-07, 3.0966e-08, 4.7963e-08,  ..., 5.0350e-09, 3.0559e-09,\n",
       "          4.4020e-10],\n",
       "         [2.1304e-08, 4.5169e-08, 2.5466e-09,  ..., 1.0623e-09, 2.3647e-10,\n",
       "          7.8580e-09],\n",
       "         [2.5332e-07, 3.6554e-08, 9.9186e-08,  ..., 1.9354e-09, 1.1714e-09,\n",
       "          1.2573e-08]], device='cuda:1', dtype=torch.bfloat16),\n",
       " torch.Size([26, 65024]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax = torch.nn.Softmax(dim=-1)\n",
    "\n",
    "performer_probs = softmax(performer_logits).view(-1, V)\n",
    "\n",
    "performer_probs, performer_probs.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c787a0c9-732e-432d-8128-a5bc5205c270",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-23.2500, -18.2500,  -9.6875,  ..., -10.6875, -12.2500,  -9.1875],\n",
       "         [-13.7500, -19.6250, -14.1250,  ..., -14.9375, -16.6250, -10.9375],\n",
       "         [-13.0625, -17.0000, -14.9375,  ..., -17.8750, -15.4375, -14.5000],\n",
       "         ...,\n",
       "         [-12.9375, -12.2500, -12.6875,  ..., -16.0000, -14.8750, -18.0000],\n",
       "         [-16.8750, -15.5625, -16.2500,  ..., -16.7500, -18.3750, -15.8125],\n",
       "         [-16.1250, -17.6250, -14.5000,  ..., -18.1250, -19.2500, -17.1250]],\n",
       "        device='cuda:1', dtype=torch.bfloat16),\n",
       " torch.Size([26, 65024]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observer_scores = observer_logits.view(-1, V).to(DEVICE_2)\n",
    "observer_scores, observer_scores.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "098f9915-0233-4543-9d48-188bac676ed1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[3.1406, 7.3750, 5.1875, 7.5000, 3.8906, 5.0312, 6.2188, 7.1250, 0.2793,\n",
       "          0.2559, 4.4375, 1.2031, 0.9180, 1.6719, 4.5000, 1.8047, 4.0312, 4.6250,\n",
       "          1.0156, 2.7656, 1.9453, 6.0000, 3.7812, 9.8125, 0.9180]],\n",
       "        device='cuda:1', dtype=torch.bfloat16),\n",
       " tensor([95.5000], device='cuda:1', dtype=torch.bfloat16))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xppl = loss(observer_scores[:-1], performer_probs[:-1]).view(-1, S - 1)\n",
    "\n",
    "xppl, xppl.sum(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a3ed0f27-05d2-4d53-ae73-8f52ada76950",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0338], device='cuda:1')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binocular_score = ppl.sum(1) / xppl.sum(1)\n",
    "\n",
    "binocular_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "91245f31-4f96-4d4a-abcd-31ee05a98074",
   "metadata": {},
   "outputs": [],
   "source": [
    "# redefine to handle batch of strings\n",
    "def tokenize(batch):\n",
    "    encodings = tokenizer(batch, return_tensors=\"pt\", \n",
    "    padding=\"longest\" if len(batch) > 1 else False, truncation=True,\n",
    "    max_length=512, return_token_type_ids=False).to(DEVICE_1)\n",
    "    return encodings\n",
    "\n",
    "# redefinition with cuda sync\n",
    "@torch.inference_mode()\n",
    "def get_logits(encodings):\n",
    "    observer_logits = observer_model(**encodings.to(DEVICE_1)).logits\n",
    "    performer_logits = performer_model(**encodings.to(DEVICE_2)).logits\n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "    return observer_logits, performer_logits\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss(reduction='none')\n",
    "softmax_fn = torch.nn.Softmax(dim=-1)\n",
    "\n",
    "def perplexity(encoding, logits):\n",
    "    shifted_logits = logits[..., :-1, :].contiguous()\n",
    "    shifted_labels = encoding.input_ids[..., 1:].contiguous()\n",
    "    shifted_attention_mask = encoding.attention_mask[..., 1:].contiguous()\n",
    "\n",
    "    ppl = loss_fn(shifted_logits.transpose(1, 2).to(DEVICE_2), shifted_labels) * shifted_attention_mask\n",
    "    ppl = ppl.sum(1) / shifted_attention_mask.sum(1)\n",
    "    \n",
    "    return ppl.to(\"cpu\").float().numpy()\n",
    "\n",
    "def cross_perplexity(observer_logits, performer_logits, encoding):\n",
    "    V = observer_logits.shape[-1]\n",
    "    S = observer_logits.shape[-2]\n",
    "\n",
    "    performer_probs = softmax_fn(performer_logits).view(-1, V).to(DEVICE_2)\n",
    "    observer_scores = observer_logits.view(-1, V).to(DEVICE_2)\n",
    "    \n",
    "    xppl = loss_fn(observer_scores, performer_probs).view(-1, S)\n",
    "    padding_mask = (encoding.input_ids != tokenizer.pad_token_id).type(torch.uint8)\n",
    "    \n",
    "    xppl = (xppl * padding_mask).sum(1) / padding_mask.sum(1)\n",
    "    \n",
    "    return xppl.cpu().float().numpy()\n",
    "\n",
    "def binocular_score(text):\n",
    "    batch = [text] if isinstance(text, str) else text\n",
    "    encodings = tokenize(batch)\n",
    "    observer_logits, performer_logits = get_logits(encodings)\n",
    "    ppl = perplexity(encodings, observer_logits)\n",
    "    xppl = cross_perplexity(observer_logits, performer_logits, encodings)\n",
    "\n",
    "    return (ppl / xppl).tolist()\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ed292996-63df-46c7-9a75-927c43249790",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.946601927280426]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tests = ['''The motivation behind LLM Detection is harm reduction, to trace text origins, block spam, and identify fake news produced by LLMs. *Preemptive detection* methods attempt to \"watermark\" generated text, but requires full control of the generating models, which already seems to be impossible. Therefore, more recent works have been on *post-hoc detection* methods, which could be used without the cooperation of the text's author. The paper's authors suggest that there are two main groups for post-hoc detectors, the first being finetuning a pretrained language model to perform binary classification. There are many additional techniques that make this approach more effective, but all implementations will require training on text produced by the target model, which is both computationally expensive and limited by the number of new models that are being open-sourced.\n",
    "The second group uses statistical signatures of machine-generated text, with the aim of zero-shot learning. This would allow for the detection of a wide range of models, with little to no training data. These methods use measures such as perplexity, perplexity curvature, log rank, intrinsic dimensionality, and n-gram analysis. The Binoculars paper proposes a focus on low false positive rate (FPR) and high performance on out-of-domain samples, rather than focusing on classifier AUCs for the high-stakes application of LLM detection.''',\n",
    "# '''Dr. Capy Cosmos, a capybara unlike any other, astounded the scientific community with his \n",
    "# groundbreaking research in astrophysics. With his keen sense of observation and unparalleled ability to interpret \n",
    "# cosmic data, he uncovered new insights into the mysteries of black holes and the origins of the universe. As he \n",
    "# peered through telescopes with his large, round eyes, fellow researchers often remarked that it seemed as if the \n",
    "# stars themselves whispered their secrets directly to him. Dr. Cosmos not only became a beacon of inspiration to \n",
    "# aspiring scientists but also proved that intellect and innovation can be found in the most unexpected of creatures.''',\n",
    "# '''We the People of the United States, in Order to form a more perfect Union, establish Justice, insure domestic Tranquility, provide for the common defence, promote the general Welfare, and secure the Blessings of Liberty to ourselves and our Posterity, do ordain and establish this Constitution for the United States of America.'''\n",
    "]\n",
    "binocular_score(tests)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6dd0e7-4e66-4a66-81c6-dfe0be5eba79",
   "metadata": {},
   "outputs": [],
   "source": [
    "1+1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1281afe7-ad18-411a-874a-558f957e191b",
   "metadata": {},
   "source": [
    "# OUT DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ccfb9b5d-6f8a-49cb-94af-5f9afc6c59d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  unique_id  \\\n",
      "0  aed3pspeai9hu7magmpk5js3hlmd67ajr2804f01   \n",
      "1  6qa9kcljo2dnsq2cffpm32uhhlmd2dhvcj940vg1   \n",
      "2  hefbgudg1vehubvhg1f62omoto7rf21rem41k901   \n",
      "3  m1anank010tp1fah6srogdmkso3rjdtb51rubmo1   \n",
      "4  18rhnb3vdmv9un43arsblhl1r4s8adb452j382g1   \n",
      "\n",
      "                                                body                 date  \\\n",
      "0                                                ...  2022-09-15 14:20:16   \n",
      "1  Top Stories @PCWorld \\r\\n\\r\\nDon’t panic! Inte...  2022-06-15 19:06:11   \n",
      "2  <!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 T...  2022-11-25 20:26:28   \n",
      "3  \\r\\n\\n--- mail_boundary ---\\n\\r\\n\\r\\n\\r\\n\\r\\n\\...  2022-08-09 09:02:27   \n",
      "4  \\r\\n\\n--- mail_boundary ---\\n\\r\\n\\r\\n\\r\\n\\r\\n\\...  2022-06-07 19:17:58   \n",
      "\n",
      "                                        cleaned_text  \n",
      "0  p r x u l e ils sont de retour version en lign...  \n",
      "1  top stories p c world dont panic intel says he...  \n",
      "2  stradivarius vite profitezen profitez du black...  \n",
      "3  mailboundary variety international breaking ne...  \n",
      "4  mailboundary variety awards circuit alert view...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load a parquet file into a pandas DataFrame\n",
    "df_before = pd.read_parquet('chatgptbefore.parquet')\n",
    "\n",
    "# Display the first few rows of the dataframe\n",
    "print(df_before.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d5f0340c-fe37-4273-a3af-adde05e4b43d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  unique_id  \\\n",
      "0  24hpi0o3m4g5j3srjijhc5ivu08qmkqt4gkrn181   \n",
      "1  f7jp9535uut6bcbljsu9ibdknpfu84vts1fsrso1   \n",
      "2  grcaba458pvs9hh88hlfnuta9el10udo63k7kh01   \n",
      "3  175s99re5e8tgupg6kjcl95l3nu4asshg9fcpsg1   \n",
      "4  rine0d5tghjb9tuk06n1889jpsn9battpninei81   \n",
      "\n",
      "                                                body                 date  \n",
      "0  *Please consider adding <info@fsf.org> to your...  2023-02-22 06:17:47  \n",
      "1  \\r\\n\\n--- mail_boundary ---\\n\\r\\n\\r\\n\\r\\n\\r\\n\\...  2023-04-13 01:05:03  \n",
      "2  Si vous n'arrivez pas à lire votre newsletter,...  2023-03-15 16:11:38  \n",
      "3  No images?  Click here https://blackdoginstitu...  2023-01-16 05:59:06  \n",
      "4  \\r\\nÉlégance artisanale\\r\\nhttps://link.email....  2023-04-24 06:04:46  \n"
     ]
    }
   ],
   "source": [
    "df_after = pd.read_parquet('chatgptafter.parquet')\n",
    "\n",
    "# Display the first few rows of the dataframe\n",
    "print(df_after.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "06416b8d-3612-4d80-849c-8d130dda9172",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 1500/1500 [09:31<00:00,  2.63it/s]\n"
     ]
    }
   ],
   "source": [
    "res_before_email=[]\n",
    "\n",
    "tmp=list(df_before.values)\n",
    "for elt in tqdm(tmp):\n",
    "    date=elt[2]\n",
    "    sentence=elt[1]\n",
    "\n",
    "    proba = binocular_score(sentence)[0]\n",
    "    \n",
    "    res_before_email+=[[sentence,proba, date]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7c493549-4987-4dae-89ae-6a6e80b8199a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 1500/1500 [09:29<00:00,  2.64it/s]\n"
     ]
    }
   ],
   "source": [
    "res_after_email=[]\n",
    "\n",
    "tmp=list(df_after.values)\n",
    "for elt in tqdm(tmp):\n",
    "    date=elt[2]\n",
    "    sentence=elt[1]\n",
    "\n",
    "    proba = binocular_score(sentence)[0]\n",
    "    \n",
    "    res_after_email+=[[sentence,proba, date]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4ac80172-386f-42cc-8c09-1dd3d1fb442c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a7382d24-54c3-47ec-af6f-9b9619451e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "f=open('results_scores_email_BINOCULAR.json','w')\n",
    "json.dump({'res_after':res_after_email,'res_before':res_before_email},f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c6d80c-515a-419b-aa09-12fb5429e568",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                               | 1/1500 [00:51<21:36:29, 51.89s/it]"
     ]
    }
   ],
   "source": [
    "res_before_para=[]\n",
    "\n",
    "tmp=list(df_before.values)\n",
    "for elt in tqdm(tmp):\n",
    "    date=elt[2]\n",
    "    for sentence in [x for x in elt[1].split('\\n') if len(x)>3]:\n",
    "        proba = binocular_score(sentence)[0]\n",
    " \n",
    "        res_before_para+=[[sentence,proba, date]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef9f54f-2579-4ad1-9119-f2e77bd2751e",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_after_para=[]\n",
    "\n",
    "tmp=list(df_after.values)\n",
    "for elt in tqdm(tmp):\n",
    "    date=elt[2]\n",
    "    for sentence in [x for x in elt[1].split('\\n') if len(x)>3]:\n",
    "        proba = binocular_score(sentence)[0]\n",
    "     \n",
    "        res_after_para+=[[sentence,proba, date]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa15a4b5-a472-478e-8ef0-82bb07a4a9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "f=open('results_scores_para_BINOCULAR.json','w')\n",
    "json.dump({'res_after':res_after_para,'res_before':res_before_para},f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a1679f-9b21-4c7f-8dd5-04f5f94de562",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_before_sent=[]\n",
    "\n",
    "tmp=list(df_before.values)\n",
    "for elt in tqdm(tmp):\n",
    "    date=elt[2]\n",
    "    for sentence in [x for x in elt[1].replace('\\n','').split('.') if len(x)>3]:\n",
    "        proba = binocular_score(sentence)[0]\n",
    "        res_before_sent+=[[sentence,proba, date]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4911c2-472f-4b6e-ba57-942d9a31248f",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_after_sent=[]\n",
    "\n",
    "tmp=list(df_after.values)\n",
    "for elt in tqdm(tmp):\n",
    "    date=elt[2]\n",
    "    for sentence in [x for x in elt[1].replace('\\n','').split('.') if len(x)>3]:\n",
    "        proba = binocular_score(sentence)[0]\n",
    "        res_after_sent+=[[sentence,proba, date]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d5177d-820d-4965-aa65-b255cdf09632",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "f=open('results_scores_sent_BINOCULAR.json','w')\n",
    "json.dump({'res_after_sent':res_after_sent,'res_before_sent':res_before_sent},f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8cd275-f4a6-4e6a-b294-217849f95702",
   "metadata": {},
   "source": [
    "# EXTRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd4ef16-7ac1-4706-9ed8-7c6887fcdc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.dpi\"] = 300\n",
    "\n",
    "capybara = '''Dr. Capy Cosmos, a capybara unlike any other, astounded the scientific community with his \n",
    "groundbreaking research in astrophysics. With his keen sense of observation and unparalleled ability to interpret \n",
    "cosmic data, he uncovered new insights into the mysteries of black holes and the origins of the universe. As he \n",
    "peered through telescopes with his large, round eyes, fellow researchers often remarked that it seemed as if the \n",
    "stars themselves whispered their secrets directly to him. Dr. Cosmos not only became a beacon of inspiration to \n",
    "aspiring scientists but also proved that intellect and innovation can be found in the most unexpected of creatures.'''\n",
    "\n",
    "encoding = tokenize([capybara])\n",
    "\n",
    "observer_logits, performer_logits = get_logits(encoding)\n",
    "\n",
    "S = observer_logits.shape[-2]\n",
    "V = observer_logits.shape[-1]\n",
    "\n",
    "(S, V)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08bfe0fe-e2d9-4eb5-9346-c4e806386a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "shifted_logits = observer_logits[..., :-1, :].contiguous()\n",
    "shifted_labels = encoding.input_ids[..., 1:].contiguous()\n",
    "\n",
    "ppl = loss_fn(shifted_logits.transpose(1, 2).to(\"cpu\"), shifted_labels).float()\n",
    "\n",
    "ppl, ppl.sum(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8079b6de-49f9-41e0-bf82-2c72300cb30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "normalized_ppl = ppl / torch.max(ppl)\n",
    "\n",
    "def generate_html(tokens, scores):\n",
    "    html = \"<p>\" + tokens[0]\n",
    "    for token, score in zip(tokens[1:], scores.squeeze().tolist()):\n",
    "        color_value = 255 * score \n",
    "        html += f\"<span style='background-color: rgb(255, {255-color_value}, {255-color_value}); color: black;'>{token}</span>\"\n",
    "    html += \"</p>\"\n",
    "    return html\n",
    "\n",
    "tokens = [tokenizer.decode([tok], clean_up_tokenization_spaces=False) for tok in encoding.input_ids.squeeze().tolist()]\n",
    "html_output = generate_html(tokens, normalized_ppl)\n",
    "\n",
    "display(HTML(html_output))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645db713-19f9-4ce0-98a1-510917894046",
   "metadata": {},
   "outputs": [],
   "source": [
    "performer_probs = softmax_fn(performer_logits).view(-1, V).to(\"cpu\")\n",
    "observer_scores = observer_logits.view(-1, V).to(\"cpu\")\n",
    "\n",
    "xppl = loss_fn(observer_scores[:-1], performer_probs[:-1]).view(-1, S - 1).to(\"cpu\").float()\n",
    "    \n",
    "xppl, xppl.sum(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382076d8-1cc4-441d-82cb-da5df63f0a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_xppl = xppl / torch.max(xppl)\n",
    "\n",
    "display(HTML(html_output))\n",
    "\n",
    "html_output = generate_html(tokens, normalized_xppl)\n",
    "display(HTML(html_output))\n",
    "\n",
    "binocular_score = normalized_ppl / normalized_xppl\n",
    "normalized_binocular_score = binocular_score / torch.max(binocular_score)\n",
    "\n",
    "html_output = generate_html(tokens, normalized_binocular_score)\n",
    "display(HTML(html_output))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5afbbf3f-6bb4-407d-90b5-f3105a1b179c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(xppl.float(), ppl.float())\n",
    "plt.title(\"Cross-Perplexity vs Perplexity\")\n",
    "plt.xlabel(\"Cross-Perplexity\")\n",
    "plt.ylabel(\"Perplexity\")\n",
    "plt.xlim(0, 12)\n",
    "plt.ylim(0, 12)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c536bde4-4e02-4782-8bcb-d832d1f14218",
   "metadata": {},
   "outputs": [],
   "source": [
    "human = '''The healthcare industry typically draws sufficient attention to patients' education, especially when it comes to representatives of minority groups. That is why the article by McCurley et al. (2017) offers valuable information. The researchers demonstrate that Hispanic individuals deal with improved diabetes prevention when they participate in individual and group face-to-face sessions (McCurley et al., 2017). I believe that there is an apparent reason why such positive outcomes are achieved. It seems that face-to-face interventions are effective because patients have an opportunity to ask questions if they require explanations. Simultaneously, such educational sessions demonstrate that a patient is not unique with such a health issue. As a result, such interventions can improve people's morale, which, in turn, will lead to increased motivation to take preventive measures and protect health.'''\n",
    "\n",
    "encoding = tokenize([human])\n",
    "\n",
    "observer_logits, performer_logits = get_logits(encoding)\n",
    "\n",
    "S = observer_logits.shape[-2]\n",
    "V = observer_logits.shape[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ca4607-1dfc-4f40-ba50-e9a00e9b81ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "shifted_logits = observer_logits[..., :-1, :].contiguous()\n",
    "shifted_labels = encoding.input_ids[..., 1:].contiguous()\n",
    "\n",
    "ppl = loss_fn(shifted_logits.transpose(1, 2).to(\"cpu\"), shifted_labels).float()\n",
    "\n",
    "normalized_ppl = ppl / torch.max(ppl)\n",
    "\n",
    "tokens = [tokenizer.decode([tok], clean_up_tokenization_spaces=False) for tok in encoding.input_ids.squeeze().tolist()]\n",
    "html_output = generate_html(tokens, normalized_ppl)\n",
    "\n",
    "display(HTML(html_output))\n",
    "\n",
    "performer_probs = softmax_fn(performer_logits).view(-1, V).to(\"cpu\")\n",
    "observer_scores = observer_logits.view(-1, V).to(\"cpu\")\n",
    "\n",
    "xppl = loss_fn(observer_scores[:-1], performer_probs[:-1]).view(-1, S - 1).to(\"cpu\").float()\n",
    "normalized_xppl = xppl / torch.max(xppl)\n",
    "\n",
    "html_output = generate_html(tokens, normalized_xppl)\n",
    "display(HTML(html_output))\n",
    "\n",
    "binocular_score = normalized_ppl / normalized_xppl\n",
    "normalized_binocular_score = binocular_score / torch.max(binocular_score)\n",
    "\n",
    "html_output = generate_html(tokens, normalized_binocular_score)\n",
    "display(HTML(html_output))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d5f77a-ba19-4fcb-938e-fb510d2cc74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(xppl.float(), ppl.float())\n",
    "plt.title(\"Cross-Perplexity vs Perplexity\")\n",
    "plt.xlabel(\"Cross-Perplexity\")\n",
    "plt.ylabel(\"Perplexity\")\n",
    "plt.xlim(0, 12)\n",
    "plt.ylim(0, 12)\n",
    "plt.show()\n",
    "\n",
    "ppl.sum(1) / xppl.sum(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca32c4f8-ddd1-4234-ab99-8428a263d00e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ForLLMLora August",
   "language": "python",
   "name": "forllmlora"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
