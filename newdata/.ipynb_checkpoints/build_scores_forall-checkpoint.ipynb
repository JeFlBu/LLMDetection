{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c9b7158-3e96-4c87-8443-be0f7f39d660",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bussotti/.conda/envs/ForLLMLora/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "# Load a parquet file into a pandas DataFrame\n",
    "\n",
    "# Display the first few rows of the dataframe\n",
    "# print(df_before.head())\n",
    "from generated_text_detector.utils.model.roberta_classifier import RobertaClassifier\n",
    "from transformers import AutoTokenizer\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d90a968-1382-42fe-8079-f50c43cac0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_before = pd.read_parquet('before_gpt.parquet')\n",
    "\n",
    "df_after = pd.read_parquet('gpt_after.parquet')\n",
    "\n",
    "# Display the first few rows of the dataframe\n",
    "# print(df_after.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d98089d-fe39-4704-ad78-b77bf6068dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install git+https://github.com/superannotateai/generated_text_detector.git@v1.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a011583d-345e-4411-a415-ee8e3989a248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "already done\n",
      "already done\n",
      "/home/bussotti/experiments grazia clara the return/newdata/strategymerge_generate\n",
      "already done\n",
      "/home/bussotti/experiments grazia clara the return/newdata/nothing\n",
      "/home/bussotti/experiments grazia clara the return/newdata/Untitled Folder\n",
      "/home/bussotti/experiments grazia clara the return/newdata/strategyrewrite_merge\n",
      "/home/bussotti/experiments grazia clara the return/newdata/strategyrewrite_generate\n",
      "/home/bussotti/experiments grazia clara the return/newdata/strategyrewrite_merge_generate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bussotti/.conda/envs/ForLLMLora/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights from local directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8800/8800 [20:24<00:00,  7.19it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [21:56<00:00,  7.60it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# Iterate through each item in the current directory\n",
    "for item in os.listdir(current_dir):\n",
    "    item_path = os.path.join(current_dir, item)\n",
    "    if '.ipynb_checkpoints' in item_path:\n",
    "        continue\n",
    "    if os.path.exists(item_path+'/results_scores_email_VARIANT061124_WITHPROB_TEMP2.json'):\n",
    "        print('already done')\n",
    "        continue\n",
    "    # Check if it's a directory\n",
    "    if not os.path.isdir(item_path):\n",
    "        continue\n",
    "    print(item_path)\n",
    "    if not os.path.exists(item_path+\"/fine_tuned_roberta_VARIANT061124_WITHPROB_TEMP2\"):\n",
    "        continue\n",
    "\n",
    "    model = RobertaClassifier.from_pretrained(item_path+\"/fine_tuned_roberta_VARIANT061124_WITHPROB_TEMP2\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(item_path+\"/fine_tuned_roberta_VARIANT061124_WITHPROB_TEMP2\")\n",
    "    model=model.to('cuda:0')\n",
    "    res_before_email=[]\n",
    "\n",
    "    tmp=list(df_before.values)[1200:]\n",
    "    for elt in tqdm(tmp):\n",
    "        date=elt[2]\n",
    "        sentence=elt[1]\n",
    "        tokens = tokenizer.encode_plus(\n",
    "            sentence,\n",
    "            add_special_tokens=True,\n",
    "            max_length=512,\n",
    "            padding='longest',\n",
    "            truncation=True,\n",
    "            return_token_type_ids=True,\n",
    "            return_tensors=\"pt\"\n",
    "        ).to('cuda:0')\n",
    "        \n",
    "        _, logits = model(**tokens)\n",
    "        \n",
    "        proba = F.sigmoid(logits).squeeze(1).item()\n",
    "        \n",
    "        res_before_email+=[[sentence,proba, date]]\n",
    "\n",
    "    res_after_email=[]\n",
    "\n",
    "    tmp=list(df_after.values)\n",
    "    for elt in tqdm(tmp):\n",
    "        date=elt[2]\n",
    "        sentence=elt[1]\n",
    "        tokens = tokenizer.encode_plus(\n",
    "            sentence,\n",
    "            add_special_tokens=True,\n",
    "            max_length=512,\n",
    "            padding='longest',\n",
    "            truncation=True,\n",
    "            return_token_type_ids=True,\n",
    "            return_tensors=\"pt\"\n",
    "        ).to('cuda:0')\n",
    "        \n",
    "        _, logits = model(**tokens)\n",
    "        \n",
    "        proba = F.sigmoid(logits).squeeze(1).item()\n",
    "        \n",
    "        res_after_email+=[[sentence,proba, date]]\n",
    "    f=open(item_path+'/results_scores_email_VARIANT061124_WITHPROB_TEMP2.json','w')\n",
    "    json.dump({'res_after':res_after_email,'res_before':res_before_email},f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb0868ed-ff69-4575-a8fb-7e76bffd7db2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3285d539-3b6a-45f9-9411-768b081e72aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_after_may=pd.read_parquet('from_may23.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6105d91-55fe-4944-9dd2-f76c99b43241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "already done\n",
      "already done\n",
      "/home/bussotti/experiments grazia clara the return/newdata/strategymerge_generate\n",
      "already done\n",
      "/home/bussotti/experiments grazia clara the return/newdata/nothing\n",
      "/home/bussotti/experiments grazia clara the return/newdata/Untitled Folder\n",
      "/home/bussotti/experiments grazia clara the return/newdata/strategyrewrite_merge\n",
      "/home/bussotti/experiments grazia clara the return/newdata/strategyrewrite_generate\n",
      "/home/bussotti/experiments grazia clara the return/newdata/strategyrewrite_merge_generate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bussotti/.conda/envs/ForLLMLora/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights from local directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20000/20000 [45:04<00:00,  7.39it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# Iterate through each item in the current directory\n",
    "for item in os.listdir(current_dir):\n",
    "    item_path = os.path.join(current_dir, item)\n",
    "    if '.ipynb_checkpoints' in item_path:\n",
    "        continue\n",
    "    if os.path.exists(item_path+'/results_scores_email_from_may23_VARIANT061124_WITHPROB_TEMP2.json'):\n",
    "        print('already done')\n",
    "        continue\n",
    "    # Check if it's a directory\n",
    "    if not os.path.isdir(item_path):\n",
    "        continue\n",
    "    print(item_path)\n",
    "    if not os.path.exists(item_path+\"/fine_tuned_roberta_VARIANT061124_WITHPROB_TEMP2\"):\n",
    "        continue\n",
    "\n",
    "    # if os.path.exists(item_path+\"/fine_tuned_roberta_model_1e-7\"):\n",
    "    model = RobertaClassifier.from_pretrained(item_path+\"/fine_tuned_roberta_VARIANT061124_WITHPROB_TEMP2\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(item_path+\"/fine_tuned_roberta_VARIANT061124_WITHPROB_TEMP2\")\n",
    "    # else:\n",
    "    #     model = RobertaClassifier.from_pretrained(\"SuperAnnotate/roberta-large-llm-content-detector\")\n",
    "    #     tokenizer = AutoTokenizer.from_pretrained(\"SuperAnnotate/roberta-large-llm-content-detector\")\n",
    "    model=model.to('cuda:0')\n",
    "\n",
    "    res_after_email=[]\n",
    "\n",
    "    tmp=list(df_after_may.values)\n",
    "    for elt in tqdm(tmp):\n",
    "        date=elt[2]\n",
    "        sentence=elt[1]\n",
    "        tokens = tokenizer.encode_plus(\n",
    "            sentence,\n",
    "            add_special_tokens=True,\n",
    "            max_length=512,\n",
    "            padding='longest',\n",
    "            truncation=True,\n",
    "            return_token_type_ids=True,\n",
    "            return_tensors=\"pt\"\n",
    "        ).to('cuda:0')\n",
    "        \n",
    "        _, logits = model(**tokens)\n",
    "        \n",
    "        proba = F.sigmoid(logits).squeeze(1).item()\n",
    "        \n",
    "        res_after_email+=[[sentence,proba, date]]\n",
    "    f=open(item_path+'/results_scores_email_from_may23_VARIANT061124_WITHPROB_TEMP2.json','w')\n",
    "    json.dump({'res':res_after_email},f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37b81d2-7e81-4f0a-9e5b-5475a2f2c767",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_after_may['body'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3212371-79c2-4f3a-aef7-29ca679749de",
   "metadata": {},
   "outputs": [],
   "source": [
    "1+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191044b5-d19c-4a6c-a9db-d0c9830a0f46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1e1679-b5c9-47fd-b808-e06e305c102b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f69ab7e-76af-4e04-95a5-1b68d864d74c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b56f04-74a5-4db8-ab87-4b8809823fc2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ForLLMLora August",
   "language": "python",
   "name": "forllmlora"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
